# Backend API Documentation

æœ¬æ–‡ä»¶è©³ç´°èªªæ˜äº† AI Agent å°ˆæ¡ˆå¾Œç«¯ API çš„æ¶æ§‹ã€ç«¯é»ã€é…ç½®å’Œé–‹ç™¼æŒ‡å—ã€‚

## ç›®éŒ„
- [æŠ€è¡“æ£§](#æŠ€è¡“æ£§)
- [é–‹å§‹ä½¿ç”¨](#é–‹å§‹ä½¿ç”¨)
  - [å‰ç½®éœ€æ±‚](#å‰ç½®éœ€æ±‚)
  - [å®‰è£](#å®‰è£)
  - [å•Ÿå‹•æœå‹™](#å•Ÿå‹•æœå‹™)
- [å°ˆæ¡ˆçµæ§‹](#å°ˆæ¡ˆçµæ§‹)
- [API ç«¯é»](#api-ç«¯é»)
  - [POST /api/v1/ai/chat/nvidia](#post-apiv1aichatnvidia)
  - [POST /api/v1/ai/chat/ollama](#post-apiv1aichatollama)
  - [GET /api/v1/ai/status](#get-apiv1aistatus)
  - [GET /api/v1/health](#get-apiv1health)
- [è«‹æ±‚/éŸ¿æ‡‰æ¨¡å‹](#è«‹æ±‚éŸ¿æ‡‰æ¨¡å‹)
- [éŒ¯èª¤è™•ç†](#éŒ¯èª¤è™•ç†)
- [æ—¥èªŒèˆ‡èª¿è©¦](#æ—¥èªŒèˆ‡èª¿è©¦)
- [ç’°å¢ƒè®Šæ•¸é…ç½®](#ç’°å¢ƒè®Šæ•¸é…ç½®)
- [æ¸¬è©¦](#æ¸¬è©¦)

## æŠ€è¡“æ£§

- **Framework**: FastAPI 0.104+
- **Language**: Python 3.10+
- **Package Manager**: uv (æ¨è–¦) æˆ– pip
- **AI Models**: 
  - Ollama (æœ¬åœ°æ¨¡å‹)
  - NVIDIA NIM (é›²ç«¯æ¨¡å‹)
- **HTTP Client**: httpx (ç•°æ­¥)
- **Configuration**: Pydantic Settings
- **Documentation**: OpenAPI/Swagger è‡ªå‹•ç”Ÿæˆ

## é–‹å§‹ä½¿ç”¨

### å‰ç½®éœ€æ±‚
- Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
- `uv` (å»ºè­°) æˆ– `pip`
- å¯é¸ï¼šOllama (ç”¨æ–¼æœ¬åœ° AI æ¨¡å‹)

### å®‰è£

```bash
# é€²å…¥å¾Œç«¯ç›®éŒ„
cd backend

# å‰µå»ºä¸¦æ¿€æ´»è™›æ“¬ç’°å¢ƒ (å¦‚æœä½¿ç”¨ pip)
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate    # Windows

# å®‰è£ä¾è³´ (ä½¿ç”¨ uv - æ¨è–¦)
uv pip install -r requirements.txt

# æˆ–ä½¿ç”¨ pip
pip install -r requirements.txt
```

### å•Ÿå‹•æœå‹™

```bash
# ä½¿ç”¨å•Ÿå‹•è…³æœ¬ (æ¨è–¦)
./start.sh

# æˆ–æ‰‹å‹•å•Ÿå‹•
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

æœå‹™å°‡é‹è¡Œåœ¨ï¼š
- **API æœå‹™**: http://localhost:8000
- **API æ–‡æª”**: http://localhost:8000/docs
- **ReDoc æ–‡æª”**: http://localhost:8000/redoc

## å°ˆæ¡ˆçµæ§‹

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/                     # API è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ v1/                  # API ç‰ˆæœ¬ 1
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ api.py           # ä¸» API è·¯ç”±å™¨
â”‚   â”‚       â””â”€â”€ endpoints/       # å„ç«¯é»æ¨¡çµ„
â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚           â”œâ”€â”€ health.py    # å¥åº·æª¢æŸ¥ç«¯é»
â”‚   â”‚           â””â”€â”€ ai_models.py # AI æ¨¡å‹ç«¯é»
â”‚   â””â”€â”€ core/                    # æ ¸å¿ƒæ‡‰ç”¨é‚è¼¯
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py            # æ‡‰ç”¨é…ç½®
â”‚       â””â”€â”€ ai_models.py         # AI æ¨¡å‹å·¥å…·
â”œâ”€â”€ .env                         # ç’°å¢ƒè®Šæ•¸ (å¾ .env-example è¤‡è£½)
â”œâ”€â”€ .env-example                 # ç’°å¢ƒè®Šæ•¸ç¯„ä¾‹
â”œâ”€â”€ main.py                      # FastAPI æ‡‰ç”¨ç¨‹å¼å…¥å£
â”œâ”€â”€ requirements.txt             # Python ä¾è³´
â”œâ”€â”€ start.sh                     # å•Ÿå‹•è…³æœ¬
â””â”€â”€ README.md                    # æœ¬æ–‡ä»¶
```

## API ç«¯é»

### POST /api/v1/ai/chat/nvidia

**åŠŸèƒ½**: èˆ‡ NVIDIA NIM DeepSeek-R1 æ¨¡å‹èŠå¤©

**è«‹æ±‚æ ¼å¼**:
```json
{
  "message": "Your chat message",
  "model": "deepseek-ai/deepseek-r1",
  "temperature": 0.7,
  "max_tokens": 1000
}
```

**éŸ¿æ‡‰æ ¼å¼**:
```json
{
  "response": "AI model response",
  "model": "deepseek-r1", 
  "timestamp": "2025-06-08T11:07:33.717811"
}
```

**æ‰€éœ€ç’°å¢ƒè®Šæ•¸**:
- `NIM_DEEPSEEK_R1_API`: NVIDIA NIM API é‡‘é‘°

**curl æ¸¬è©¦ç¯„ä¾‹**:
```bash
curl -X 'POST' \
  'http://localhost:8000/api/v1/ai/chat/nvidia' \
  -H 'Content-Type: application/json' \
  -d '{
    "message": "Hello, how are you?",
    "model": "deepseek-ai/deepseek-r1",
    "temperature": 0.7,
    "max_tokens": 1000
  }'
```

### POST /api/v1/ai/chat/ollama

**åŠŸèƒ½**: èˆ‡æœ¬åœ° Ollama æ¨¡å‹èŠå¤©

**è«‹æ±‚æ ¼å¼**:
```json
{
  "message": "Your chat message",
  "temperature": 0.7,
  "max_tokens": 1000
}
```

**éŸ¿æ‡‰æ ¼å¼**:
```json
{
  "response": "AI model response",
  "model": "qwen2:7b",
  "timestamp": "2025-06-08T11:07:33.717811"
}
```

**æ‰€éœ€ç’°å¢ƒè®Šæ•¸**:
- `OLLAMA_API_BASE`: Ollama æœå‹™åœ°å€ (é è¨­: http://127.0.0.1:11434)
- `OLLAMA_MODEL`: ä½¿ç”¨çš„æ¨¡å‹åç¨± (é è¨­: qwen2:7b)

### GET /api/v1/ai/status

**åŠŸèƒ½**: æª¢æŸ¥ AI æœå‹™ç‹€æ…‹

**éŸ¿æ‡‰æ ¼å¼**:
```json
{
  "ollama": {
    "available": true,
    "url": "http://127.0.0.1:11434",
    "models_count": 3
  },
  "nvidia_nim": {
    "available": true
  }
}
```

### GET /api/v1/health

**åŠŸèƒ½**: å¥åº·æª¢æŸ¥ç«¯é»

**éŸ¿æ‡‰æ ¼å¼**:
```json
{
  "status": "healthy",
  "timestamp": "2025-06-08T11:07:33.717811"
}
```

## è«‹æ±‚/éŸ¿æ‡‰æ¨¡å‹

### Pydantic æ¨¡å‹å®šç¾©

```python
from pydantic import BaseModel
from typing import Optional
from datetime import datetime

class ChatRequest(BaseModel):
    """èŠå¤©è«‹æ±‚æ¨¡å‹"""
    message: str
    model: Optional[str] = None
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 1000

class ChatResponse(BaseModel):
    """èŠå¤©éŸ¿æ‡‰æ¨¡å‹"""
    response: str
    model: str
    timestamp: str

class HealthResponse(BaseModel):
    """å¥åº·æª¢æŸ¥éŸ¿æ‡‰æ¨¡å‹"""
    status: str
    timestamp: str
```

## éŒ¯èª¤è™•ç†

### HTTP ç‹€æ…‹ç¢¼

- **200 OK**: è«‹æ±‚æˆåŠŸ
- **400 Bad Request**: è«‹æ±‚åƒæ•¸éŒ¯èª¤æˆ–é…ç½®ç¼ºå¤±
- **422 Unprocessable Entity**: è«‹æ±‚æ ¼å¼éŒ¯èª¤
- **500 Internal Server Error**: æœå‹™å™¨å…§éƒ¨éŒ¯èª¤

### éŒ¯èª¤éŸ¿æ‡‰æ ¼å¼

```json
{
  "detail": "Error message description"
}
```

### å¸¸è¦‹éŒ¯èª¤

#### 422 Unprocessable Entity
```json
{
  "detail": [
    {
      "loc": ["body", "message"],
      "msg": "field required",
      "type": "value_error.missing"
    }
  ]
}
```
**è§£æ±ºæ–¹æ¡ˆ**: æª¢æŸ¥è«‹æ±‚é«”æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µï¼Œç¢ºèª Content-Type ç‚º `application/json`

#### 400 Bad Request
```json
{
  "detail": "NVIDIA NIM API key not configured"
}
```
**è§£æ±ºæ–¹æ¡ˆ**: è¨­å®šç›¸æ‡‰çš„ç’°å¢ƒè®Šæ•¸ (å¦‚ `NIM_DEEPSEEK_R1_API`)

#### 500 Internal Server Error
```json
{
  "detail": "Error communicating with NVIDIA NIM: [specific error]"
}
```
**è§£æ±ºæ–¹æ¡ˆ**: æª¢æŸ¥ AI æœå‹™é€£æ¥ï¼Œç¢ºèª API é‡‘é‘°æœ‰æ•ˆ

## æ—¥èªŒèˆ‡èª¿è©¦

### è«‹æ±‚æ—¥èªŒä¸­é–“ä»¶

æ‡‰ç”¨åŒ…å«è©³ç´°çš„è«‹æ±‚æ—¥èªŒè¨˜éŒ„ï¼š

```python
# åœ¨æ§åˆ¶å°ä¸­æœƒçœ‹åˆ°é¡ä¼¼è¼¸å‡ºï¼š
ğŸŒ Incoming request to /api/v1/ai/chat/nvidia
  - Method: POST
  - Headers: {'content-type': 'application/json', ...}
  - Body (parsed): {'message': 'Hello', 'model': 'deepseek-ai/deepseek-r1', ...}
  - Body type: <class 'dict'>
```

### èª¿è©¦ç«¯é»è«‹æ±‚

```python
# ai_models.py ä¸­çš„èª¿è©¦ä¿¡æ¯
ğŸ” NVIDIA endpoint received request:
  - Type: <class 'app.api.v1.endpoints.ai_models.ChatRequest'>
  - Message: Hello
  - Model: deepseek-ai/deepseek-r1
  - Temperature: 0.7
  - Max tokens: 1000
```

### æ—¥èªŒç´šåˆ¥é…ç½®

```bash
# .env æ–‡ä»¶ä¸­è¨­å®š
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
DEBUG=true      # é–‹ç™¼ç’°å¢ƒèª¿è©¦æ¨¡å¼
```

## ç’°å¢ƒè®Šæ•¸é…ç½®

### å¿…è¦é…ç½®

```bash
# AI æ¨¡å‹ API é‡‘é‘°
NIM_DEEPSEEK_R1_API=your_nvidia_api_key_here

# Ollama é…ç½®
OLLAMA_API_BASE=http://127.0.0.1:11434
OLLAMA_MODEL=qwen2:7b
OLLAMA_CONTEXT_LENGTH=8192

# æ‡‰ç”¨é…ç½®
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# å®‰å…¨æ€§ (ç”Ÿç”¢ç’°å¢ƒå¿…è¦)
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=30

# CORS è¨­å®š
ALLOWED_HOSTS=["http://localhost:3000", "http://127.0.0.1:3000"]
```

### é…ç½®é©—è­‰

```bash
# ä½¿ç”¨å¥åº·æª¢æŸ¥è…³æœ¬é©—è­‰é…ç½®
cd ..  # è¿”å›æ ¹ç›®éŒ„
./health-check.sh
```

## æ¸¬è©¦

### å–®å…ƒæ¸¬è©¦

```bash
# åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
python -m pytest

# åŸ·è¡Œç‰¹å®šæ¸¬è©¦æ–‡ä»¶
python -m pytest test_ai_models.py -v

# åŸ·è¡Œç‰¹å®šæ¸¬è©¦
python -m pytest test_ai_models.py::test_nvidia_chat -v
```

### API æ¸¬è©¦

```bash
# ä½¿ç”¨æä¾›çš„æ¸¬è©¦è…³æœ¬
python test.py

# æ‰‹å‹• curl æ¸¬è©¦
curl -X GET http://localhost:8000/api/v1/health
curl -X GET http://localhost:8000/api/v1/ai/status
```

### è² è¼‰æ¸¬è©¦

```bash
# ä½¿ç”¨ ab (Apache Bench)
ab -n 100 -c 10 http://localhost:8000/api/v1/health

# ä½¿ç”¨ hey
hey -n 100 -c 10 http://localhost:8000/api/v1/health
```

## æ€§èƒ½è€ƒé‡

### AI æ¨¡å‹éŸ¿æ‡‰æ™‚é–“
- **NVIDIA NIM**: é€šå¸¸ 10-60 ç§’
- **Ollama**: å–æ±ºæ–¼æœ¬åœ°ç¡¬é«”ï¼Œé€šå¸¸ 5-30 ç§’
- **å»ºè­°**: å‰ç«¯è¨­ç½®è‡³å°‘ 120 ç§’è¶…æ™‚

### ä¸¦ç™¼è™•ç†
- FastAPI æ”¯æ´ç•°æ­¥è™•ç†
- ä½¿ç”¨ `httpx.AsyncClient` é€²è¡Œéé˜»å¡ HTTP è«‹æ±‚
- å»ºè­°ç”Ÿç”¢ç’°å¢ƒä½¿ç”¨ Gunicorn + Uvicorn

### è³‡æºç›£æ§

```bash
# ç›£æ§æœå‹™ç‹€æ…‹
curl http://localhost:8000/api/v1/ai/status

# æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨
ps aux | grep python

# æª¢æŸ¥ç¶²çµ¡é€£æ¥
netstat -an | grep 8000
```

## API å®¢æˆ¶ç«¯æ•´åˆæŒ‡å—

### å¿…è¦ Headers

```javascript
{
  'Content-Type': 'application/json',
  'Accept': 'application/json'
}
```

### éŒ¯èª¤è™•ç†æœ€ä½³å¯¦è¸

```javascript
try {
  const response = await fetch('/api/v1/ai/chat/nvidia', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(requestData)
  });
  
  if (!response.ok) {
    const errorData = await response.json();
    throw new Error(errorData.detail);
  }
  
  const result = await response.json();
  return result;
} catch (error) {
  console.error('API Error:', error);
  throw error;
}
```

### è¶…æ™‚è™•ç†

```javascript
const controller = new AbortController();
setTimeout(() => controller.abort(), 120000); // 120 ç§’

fetch(url, {
  signal: controller.signal,
  // ... other options
});
```

---

**å¦‚éœ€æ›´å¤šæŠ€è¡“æ”¯æ´ï¼Œè«‹æŸ¥çœ‹ FastAPI å®˜æ–¹æ–‡æª”æˆ–åœ¨å°ˆæ¡ˆä¸­é–‹å•Ÿ issueã€‚**
